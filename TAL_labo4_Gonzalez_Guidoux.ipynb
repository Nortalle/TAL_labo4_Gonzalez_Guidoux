{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours TAL – Labo 3 : analyse syntaxique\n",
    "Nathan Gonzalez Montes et Vincent Guidoux\n",
    "\n",
    "## Exercice 1\n",
    "\n",
    "### Manipulations\n",
    "D'abord, on réalise les tests de performance avec le fichier obtenu `UD_French.gz` sur les fichier `fr-ud-test.conllu3` et `fr-ud-dev.conllu3` et on vérifie les résultats. Après avoir testé, on réalise un entraînement avec le fichier `fr-ud-train.conllu3` en reprenant comme model le même fichier qu'avant, en modifiant le nom pour avoir notre propre fichier entraîné (on a mis `UD_French_train.gz` comme nom, ). Après la réalisation de l'entraînement, on relance les tests de performance avec le fichier entraîné pour voir la différence dans le résultats (améliorés grâce à l'entraînement).\n",
    "\n",
    "### Test sans entraînement\n",
    "#### Test file\n",
    "##### Dans la ligne de commande:\n",
    "`java -mx2000m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.nndep.DependencyParser -t\n",
    "estFile data/fr-ud-test.conllu3 -model data/UD_French.gz`\n",
    "\n",
    "Loading depparse model: data/UD_French.gz ...\n",
    "###################\n",
    "#Transitions: 81\n",
    "#Labels: 40\n",
    "\n",
    "ROOTLABEL: root\n",
    "\n",
    "PreComputed 99996, Elapsed Time: 15.279 (s)\n",
    "\n",
    "Initializing dependency parser ... done [16.6 sec].\n",
    "\n",
    "Test File: data/fr-ud-test.conllu3\n",
    "\n",
    "OOV Words: 608 / 10020 = 6.07%\n",
    "\n",
    "UAS = 55.0699\n",
    "\n",
    "LAS = 41.1577\n",
    "\n",
    "DependencyParser parsed 10020 words in 416 sentences in 4.7s at 2129.2 w/s, 88.4 sent/s.\n",
    "\n",
    "#### Dev file\n",
    "##### Dans la ligne de commande:\n",
    "`java -mx2000m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.nndep.DependencyParser -t\n",
    "estFile data/fr-ud-dev.conllu3 -model data/UD_French.gz`\n",
    "\n",
    "Loading depparse model: data/UD_French.gz ...\n",
    "###################\n",
    "\n",
    "#Transitions: 81\n",
    "\n",
    "#Labels: 40\n",
    "\n",
    "ROOTLABEL: root\n",
    "\n",
    "PreComputed 99996, Elapsed Time: 16.44 (s)\n",
    "\n",
    "Initializing dependency parser ... done [17.8 sec].\n",
    "\n",
    "Test File: data/fr-ud-dev.conllu3\n",
    "\n",
    "OOV Words: 2716 / 35771 = 7.59%\n",
    "\n",
    "UAS = 57.2195\n",
    "\n",
    "LAS = 43.6722\n",
    "\n",
    "DependencyParser parsed 10020 words in 1478 sentences in 18.1s at 1972.4 w/s, 81.5 sent/s.\n",
    "\n",
    "\n",
    "### Test avec entraînement\n",
    "#### Entraînement\n",
    "##### Dans la ligne de commande:\n",
    "`java -mx2000m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.nndep.DependencyParser -trainFile data/fr-ud-train.conllu3 -model data/UD_French_train.gz -wordCutOff 3 -trainingThreads 6 -maxIter 5000`\n",
    "\n",
    "`-wordCutOff 3` - Pour traiter seulement les mots apparaissant plus de 3 fois, ce qui évite le problème des nombres – uniques – avec un espace.\n",
    "\n",
    "`‑trainingThreads 8` - Pour utiliser pleinement son processeur, indiquer le maximum selon le model de la documentation (On our 16-core test machines: a batch size of 10,000 runs fastest with around 6 threads; a batch size of 100,000 runs best with around 10 threads)\n",
    "\n",
    "`‑maxIter 5000` - Pour arrêter l’entraînement après 5'000 itérations, de base il fait 20'000 itérations.\n",
    "\n",
    "#### Test file\n",
    "##### Dans la ligne de commande:\n",
    "`java -mx2000m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.nndep.DependencyParser -t\n",
    "estFile data/fr-ud-test.conllu3 -model data/UD_French_train.gz`\n",
    "\n",
    "Loading depparse model: data/UD_French_train.gz ...\n",
    "###################\n",
    "#Transitions: 91\n",
    "#Labels: 45\n",
    "\n",
    "ROOTLABEL: root\n",
    "\n",
    "PreComputed 100000, Elapsed Time: 1.226 (s)\n",
    "\n",
    "Initializing dependency parser ... done [3.0 sec].\n",
    "\n",
    "Test File: data/fr-ud-test.conllu3\n",
    "\n",
    "OOV Words: 1100 / 10020 = 10.98%\n",
    "\n",
    "UAS = 77.8842\n",
    "\n",
    "LAS = 71.4571\n",
    "\n",
    "DependencyParser parsed 10020 words in 416 sentences in 1.4s at 7308.5 w/s, 303.4 sent/s.\n",
    "\n",
    "\n",
    "#### Dev file\n",
    "##### Dans la ligne de commande:\n",
    "`java -mx2000m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.nndep.DependencyParser -t\n",
    "estFile data/fr-ud-dev.conllu3 -model data/UD_French_train.gz`\n",
    "\n",
    "Loading depparse model: data/UD_French_train.gz ...\n",
    "###################\n",
    "#Transitions: 91\n",
    "#Labels: 45\n",
    "\n",
    "ROOTLABEL: root\n",
    "\n",
    "PreComputed 100000, Elapsed Time: 1.497 (s)\n",
    "\n",
    "Initializing dependency parser ... done [2.7 sec].\n",
    "\n",
    "Test File: data/fr-ud-dev.conllu3\n",
    "\n",
    "OOV Words: 4724 / 35771 = 13.21%\n",
    "\n",
    "UAS = 80.5094\n",
    "\n",
    "LAS = 74.5241\n",
    "\n",
    "DependencyParser parsed 35771 words in 1478 sentences in 2.7s at 13165.6 w/s, 544.0 sent/s.\n",
    "\n",
    "### Question\n",
    "Quel est le score du modèle fourni, et quel est le score du modèle que vous avez entraîné ?\n",
    "\n",
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "from collections import Counter\n",
    "from nltk.parse import (\n",
    "    DependencyGraph,\n",
    "    ProjectiveDependencyParser,\n",
    "    NonprojectiveDependencyParser,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vous devez lire le(s) fichier(s) UD phrase par phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "filepath = 'data/fr-ud-test.conllu3'  \n",
    "dependency_graphs = []\n",
    "\n",
    "try:  \n",
    "    fp = open(filepath, 'r',encoding=\"utf-8\")\n",
    "    raw_sentences = fp.read().split('\\n\\n')\n",
    "finally:  \n",
    "    fp.close()\n",
    "\n",
    "nbr_raw_sents = len(raw_sentences) - 1 ## the file end with 4 '\\n'\n",
    "    \n",
    "for i in range(nbr_raw_sents):\n",
    "    try:\n",
    "        dependency_graphs.append(DependencyGraph(raw_sentences[i], top_relation_label='root'))\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il faut ensuite extraire les triplets ayant une relation ‘nsubj’ (entre sujet et verbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubj_triples = []\n",
    "\n",
    "for dependency_graph in dependency_graphs:\n",
    "    for head, rel, dep in dependency_graph.triples():\n",
    "        if rel == 'nsubj':\n",
    "            nsubj_triples.append((head, dep))\n",
    "            \n",
    "occurences = Counter(nsubj_triples)\n",
    "\n",
    "# sorted_by_second = sorted(list(occurences.items()), key=lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quels sont les 10 triplets les plus fréquents dans tout le corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Il a\" occure 7 fois \n",
      "\"on peut\" occure 4 fois \n",
      "\"il a\" occure 4 fois \n",
      "\"c' est\" occure 3 fois \n",
      "\"il contrôle\" occure 3 fois \n",
      "\"il faut\" occure 3 fois \n",
      "\"qui font\" occure 2 fois \n",
      "\"elle guette\" occure 2 fois \n",
      "\"vous avez\" occure 2 fois \n",
      "\"je vois\" occure 2 fois \n"
     ]
    }
   ],
   "source": [
    "# sorted_by_second[:10]\n",
    "occurences.most_common(10)\n",
    "\n",
    "for (triplet, nbr_occurences) in occurences.most_common(10):\n",
    "    print('\"{pron} {verb}\" occure {nbr_occurences} fois '.format(\n",
    "        pron=triplet[1][0],\n",
    "        verb=triplet[0][0],\n",
    "        nbr_occurences=nbr_occurences,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3\n",
    "\n",
    "### Démarrer le serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !java -mx4g -cp \"stanford-corenlp-3.9.2.jar;stanford-corenlp-3.9.2-models-french.jar\" edu.stanford.nlp.pipeline.StanfordCoreNcd LPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-124595c77397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoreNLPParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://localhost:9000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nortalle\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\nltk\\parse\\corenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url, encoding, tagtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://localhost:9000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "parser = CoreNLPParser(url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
